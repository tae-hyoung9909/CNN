{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5b99c8-d9d8-4abc-84c2-b31337287929",
   "metadata": {},
   "source": [
    "# SGD(Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb24763c-5c53-4b5c-96ee-cc7d31ee3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "boston_df = pd.read_csv(\"./boston_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2aca30e-c712-49ef-932d-7f2a571b6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, target_sgd, learning_rate=0.01):\n",
    "    # 데이터 건수\n",
    "    N = target_sgd.shape[0]\n",
    "    # 예측 값. \n",
    "    predicted_sgd = w1 * rm_sgd + w2 * lstat_sgd + bias\n",
    "    # 실제값과 예측값의 차이\n",
    "    diff_sgd = target_sgd - predicted_sgd \n",
    "    \n",
    "    # weight와 bias를 얼마나 update할 것인지를 계산.  \n",
    "    w1_update = -(2/N) * learning_rate * (torch.matmul(rm_sgd, diff_sgd))\n",
    "    w2_update = -(2/N) * learning_rate * (torch.matmul(lstat_sgd, diff_sgd))\n",
    "    bias_update = -(2/N) * learning_rate * torch.sum(diff_sgd)\n",
    "    \n",
    "    # weight와 bias가 update되어야 할 값 반환. \n",
    "    return bias_update, w1_update, w2_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09446e79-35c6-4c4b-ac9d-76added462d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_gradient_descent(features, target, iter_epochs=1000, learning_rate=0.01, verbose=True):\n",
    "    torch.manual_seed(2025)\n",
    "\n",
    "    w1 = torch.zeros(1, dtype=torch.float32)\n",
    "    w2 = torch.zeros(1, dtype=torch.float32)\n",
    "    bias = torch.ones(1, dtype=torch.float32)\n",
    "    print('최초 w1, w2, bias:', w1.item(), w2.item(), bias.item())\n",
    "    \n",
    "    rm = features[:, 0]\n",
    "    lstat = features[:, 1]\n",
    "    \n",
    "    for i in range(1, iter_epochs+1):\n",
    "        ######### 바뀐 부분 #########\n",
    "        stochastic_index = torch.randint(0, target.shape[0], size=(1,))\n",
    "        rm_sgd = rm[stochastic_index]\n",
    "        lstat_sgd = lstat[stochastic_index]\n",
    "        target_sgd = target[stochastic_index]\n",
    "        \n",
    "        bias_update, w1_update, w2_update = get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, \n",
    "                                                                     target_sgd, learning_rate=0.01)\n",
    "\n",
    "        w1 = w1 - w1_update\n",
    "        w2 = w2 - w2_update\n",
    "        bias = bias - bias_update\n",
    "        if verbose: # 100회 iteration 시마다 출력\n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch: {i}/{iter_epochs}')\n",
    "                # Loss는 전체 학습 데이터 기반으로 구해야 함. 아래는 전체 학습 feature 기반의 예측 및 loss임.  \n",
    "                predicted = w1 * rm + w2*lstat + bias\n",
    "                diff = target - predicted\n",
    "                loss = torch.mean(diff ** 2)\n",
    "                print(f'w1: {w1.item()}, w2: {w2.item()}, bias: {bias.item()}, loss: {loss.item()}')\n",
    "        \n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ad01ea-2a81-4b9e-9eb6-23192cabcdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_ftr_ts shape:torch.Size([354, 2]) tr_tgt_ts shape:torch.Size([354])\n",
      "test_ftr_ts shape:torch.Size([152, 2]) test_tgt_ts shape: torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습과 테스트용 feature와 target 분리. \n",
    "def get_scaled_train_test_feature_target_ts(data_df):\n",
    "    # RM, LSTAT Feature에 Scaling 적용\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features_np = scaler.fit_transform(data_df[['RM', 'LSTAT']])\n",
    "    # 학습 feature, 테스트 feature, 학습 target, test_target으로 분리. \n",
    "    tr_features, test_features, tr_target, test_target = train_test_split(scaled_features_np, \n",
    "                                                                          data_df['PRICE'].values, \n",
    "                                                                          test_size=0.3, random_state=2025)\n",
    "    # 학습 feature와 target을 tensor로 변환. \n",
    "    tr_ftr_ts = torch.from_numpy(tr_features)\n",
    "    tr_tgt_ts = torch.from_numpy(tr_target)\n",
    "    test_ftr_ts = torch.from_numpy(test_features)\n",
    "    test_tgt_ts = torch.from_numpy(test_target)\n",
    "    \n",
    "    return tr_ftr_ts, tr_tgt_ts, test_ftr_ts, test_tgt_ts\n",
    "\n",
    "tr_ftr_ts, tr_tgt_ts, test_ftr_ts, test_tgt_ts = get_scaled_train_test_feature_target_ts(data_df=boston_df)\n",
    "\n",
    "print(f\"tr_ftr_ts shape:{tr_ftr_ts.shape} tr_tgt_ts shape:{tr_tgt_ts.shape}\")\n",
    "print(f\"test_ftr_ts shape:{test_ftr_ts.shape} test_tgt_ts shape: {test_tgt_ts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28a8743f-7c94-4154-b480-b83620d706c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 w1, w2, bias: 0.0 0.0 1.0\n",
      "Epoch: 100/5000\n",
      "w1: 9.10193920135498, w2: 2.380099058151245, bias: 16.32122802734375, loss: 79.20577943326704\n",
      "Epoch: 200/5000\n",
      "w1: 11.38884162902832, w2: 0.6377108693122864, bias: 17.6075439453125, loss: 72.33473168920669\n",
      "Epoch: 300/5000\n",
      "w1: 11.43453311920166, w2: -1.9443591833114624, bias: 15.634873390197754, loss: 67.57221355061512\n",
      "Epoch: 400/5000\n",
      "w1: 13.544651985168457, w2: -3.477250814437866, bias: 16.884212493896484, loss: 59.431842244690046\n",
      "Epoch: 500/5000\n",
      "w1: 14.300559997558594, w2: -5.690975189208984, bias: 16.270288467407227, loss: 54.669107955151254\n",
      "Epoch: 600/5000\n",
      "w1: 15.722941398620605, w2: -7.305695056915283, bias: 16.813228607177734, loss: 50.19557187179603\n",
      "Epoch: 700/5000\n",
      "w1: 16.91908073425293, w2: -8.649571418762207, bias: 16.845500946044922, loss: 47.19992843074546\n",
      "Epoch: 800/5000\n",
      "w1: 17.07891273498535, w2: -10.086063385009766, bias: 16.271669387817383, loss: 45.02960586768405\n",
      "Epoch: 900/5000\n",
      "w1: 17.974334716796875, w2: -10.912721633911133, bias: 16.860803604125977, loss: 43.13543139188086\n",
      "Epoch: 1000/5000\n",
      "w1: 19.121231079101562, w2: -12.040255546569824, bias: 17.315248489379883, loss: 41.94179084124044\n",
      "Epoch: 1100/5000\n",
      "w1: 20.00320053100586, w2: -12.928214073181152, bias: 17.46938133239746, loss: 41.24387989438162\n",
      "Epoch: 1200/5000\n",
      "w1: 20.05638313293457, w2: -14.566816329956055, bias: 16.150402069091797, loss: 37.80478263287195\n",
      "Epoch: 1300/5000\n",
      "w1: 20.772939682006836, w2: -15.309930801391602, bias: 16.36229705810547, loss: 36.61034035781944\n",
      "Epoch: 1400/5000\n",
      "w1: 21.104564666748047, w2: -15.909236907958984, bias: 16.537328720092773, loss: 35.97110925138093\n",
      "Epoch: 1500/5000\n",
      "w1: 21.57444190979004, w2: -16.55977439880371, bias: 17.088714599609375, loss: 35.77495375347576\n",
      "Epoch: 1600/5000\n",
      "w1: 22.142423629760742, w2: -17.44516372680664, bias: 16.611204147338867, loss: 34.48722751431401\n",
      "Epoch: 1700/5000\n",
      "w1: 22.47092056274414, w2: -18.099706649780273, bias: 16.778505325317383, loss: 34.061999716999175\n",
      "Epoch: 1800/5000\n",
      "w1: 22.78106689453125, w2: -18.82854652404785, bias: 16.28932762145996, loss: 33.4037884312053\n",
      "Epoch: 1900/5000\n",
      "w1: 23.08369255065918, w2: -18.89620590209961, bias: 16.6461181640625, loss: 33.39054527330694\n",
      "Epoch: 2000/5000\n",
      "w1: 24.051511764526367, w2: -19.0889835357666, bias: 17.2291202545166, loss: 34.84234860959225\n",
      "Epoch: 2100/5000\n",
      "w1: 23.762985229492188, w2: -19.80048942565918, bias: 16.149364471435547, loss: 32.66716410320566\n",
      "Epoch: 2200/5000\n",
      "w1: 24.598045349121094, w2: -20.556318283081055, bias: 15.910174369812012, loss: 32.21486544929298\n",
      "Epoch: 2300/5000\n",
      "w1: 24.60232162475586, w2: -20.54950523376465, bias: 15.71094036102295, loss: 32.2891678277514\n",
      "Epoch: 2400/5000\n",
      "w1: 24.818513870239258, w2: -20.363372802734375, bias: 16.16160774230957, loss: 32.3458161438385\n",
      "Epoch: 2500/5000\n",
      "w1: 24.697647094726562, w2: -20.653650283813477, bias: 15.435808181762695, loss: 32.4503059893132\n",
      "Epoch: 2600/5000\n",
      "w1: 25.4434814453125, w2: -20.53604507446289, bias: 16.401548385620117, loss: 32.79919474983876\n",
      "Epoch: 2700/5000\n",
      "w1: 25.788400650024414, w2: -21.01487159729004, bias: 16.360788345336914, loss: 32.606421312207004\n",
      "Epoch: 2800/5000\n",
      "w1: 25.21722984313965, w2: -20.946958541870117, bias: 15.393991470336914, loss: 32.14667826013999\n",
      "Epoch: 2900/5000\n",
      "w1: 25.390108108520508, w2: -21.061168670654297, bias: 15.430625915527344, loss: 32.025750437446575\n",
      "Epoch: 3000/5000\n",
      "w1: 25.172073364257812, w2: -21.104637145996094, bias: 14.925098419189453, loss: 32.83436414240379\n",
      "Epoch: 3100/5000\n",
      "w1: 25.386938095092773, w2: -21.047924041748047, bias: 15.322564125061035, loss: 32.10604528089874\n",
      "Epoch: 3200/5000\n",
      "w1: 25.70531463623047, w2: -20.95286750793457, bias: 15.742814064025879, loss: 31.96027078098366\n",
      "Epoch: 3300/5000\n",
      "w1: 25.53109359741211, w2: -20.67476463317871, bias: 15.849411964416504, loss: 32.112134608603675\n",
      "Epoch: 3400/5000\n",
      "w1: 25.728376388549805, w2: -21.227209091186523, bias: 15.922232627868652, loss: 31.942119637675113\n",
      "Epoch: 3500/5000\n",
      "w1: 25.518665313720703, w2: -22.177976608276367, bias: 14.984235763549805, loss: 32.72131001200209\n",
      "Epoch: 3600/5000\n",
      "w1: 25.772300720214844, w2: -22.36690902709961, bias: 15.414904594421387, loss: 31.88385087189684\n",
      "Epoch: 3700/5000\n",
      "w1: 26.16721534729004, w2: -22.69513511657715, bias: 15.926135063171387, loss: 31.549508619910775\n",
      "Epoch: 3800/5000\n",
      "w1: 26.23098373413086, w2: -22.985837936401367, bias: 15.591504096984863, loss: 31.59232540446131\n",
      "Epoch: 3900/5000\n",
      "w1: 26.651042938232422, w2: -22.549259185791016, bias: 16.273193359375, loss: 32.08472303866568\n",
      "Epoch: 4000/5000\n",
      "w1: 26.042081832885742, w2: -22.9172420501709, bias: 15.747186660766602, loss: 31.56816360109441\n",
      "Epoch: 4100/5000\n",
      "w1: 25.85407066345215, w2: -22.375118255615234, bias: 16.286142349243164, loss: 31.75578748323248\n",
      "Epoch: 4200/5000\n",
      "w1: 26.224689483642578, w2: -22.50276756286621, bias: 16.39626693725586, loss: 31.99042641726932\n",
      "Epoch: 4300/5000\n",
      "w1: 25.857444763183594, w2: -22.9141902923584, bias: 16.264211654663086, loss: 31.573671850259654\n",
      "Epoch: 4400/5000\n",
      "w1: 26.24478530883789, w2: -22.943714141845703, bias: 16.3443660736084, loss: 31.738931356081054\n",
      "Epoch: 4500/5000\n",
      "w1: 26.42640495300293, w2: -23.301311492919922, bias: 16.27486801147461, loss: 31.63073766374232\n",
      "Epoch: 4600/5000\n",
      "w1: 26.559219360351562, w2: -23.77950096130371, bias: 16.16883659362793, loss: 31.496410986638498\n",
      "Epoch: 4700/5000\n",
      "w1: 26.367219924926758, w2: -23.969533920288086, bias: 15.635705947875977, loss: 31.67656482317143\n",
      "Epoch: 4800/5000\n",
      "w1: 26.740177154541016, w2: -23.788829803466797, bias: 15.994451522827148, loss: 31.4679915938718\n",
      "Epoch: 4900/5000\n",
      "w1: 27.248546600341797, w2: -23.64810562133789, bias: 16.62917709350586, loss: 32.61397646568802\n",
      "Epoch: 5000/5000\n",
      "w1: 27.299787521362305, w2: -24.172941207885742, bias: 16.071279525756836, loss: 31.611807798171824\n",
      "##### 최종 w1, w2, bias #######\n",
      "tensor([27.2998]) tensor([-24.1729]) tensor([16.0713])\n"
     ]
    }
   ],
   "source": [
    "# 학습 feature와 target으로 Stochastic Gradient Descent 수행. \n",
    "w1, w2, bias = st_gradient_descent(tr_ftr_ts, tr_tgt_ts, iter_epochs=5000, verbose=True)\n",
    "print('##### 최종 w1, w2, bias #######')\n",
    "print(w1, w2, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c9fc728-a095-4e71-bb9a-3df830dfd011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57750527 0.08967991]\n",
      " [0.5479977  0.2044702 ]\n",
      " [0.6943859  0.06346578]\n",
      " ...\n",
      " [0.65433991 0.10789183]\n",
      " [0.61946733 0.13107064]\n",
      " [0.47307913 0.16970199]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features_np = scaler.fit_transform(boston_df[['RM', 'LSTAT']])\n",
    "\n",
    "print(scaled_features_np)\n",
    "\n",
    "tr_features, test_features, tr_target, test_target = train_test_split(scaled_features_np, boston_df['PRICE'].values, \n",
    "                                                                      test_size=0.3, random_state=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845af042-92db-42ef-b10c-30c9a0b566b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PREDICTED_PRICE_SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.504311</td>\n",
       "      <td>0.546082</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.638467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.727534</td>\n",
       "      <td>0.082781</td>\n",
       "      <td>31.5</td>\n",
       "      <td>33.931732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442422</td>\n",
       "      <td>0.348786</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.718124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.443380</td>\n",
       "      <td>0.197296</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23.406238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.519640</td>\n",
       "      <td>0.139349</td>\n",
       "      <td>24.1</td>\n",
       "      <td>26.888865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.511401</td>\n",
       "      <td>0.309051</td>\n",
       "      <td>20.1</td>\n",
       "      <td>22.561742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.425752</td>\n",
       "      <td>0.450607</td>\n",
       "      <td>22.5</td>\n",
       "      <td>16.801722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.612569</td>\n",
       "      <td>0.049669</td>\n",
       "      <td>32.4</td>\n",
       "      <td>31.593653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.623683</td>\n",
       "      <td>0.061258</td>\n",
       "      <td>31.6</td>\n",
       "      <td>31.616892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.571757</td>\n",
       "      <td>0.533940</td>\n",
       "      <td>10.9</td>\n",
       "      <td>18.773215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.498755</td>\n",
       "      <td>0.544426</td>\n",
       "      <td>21.7</td>\n",
       "      <td>16.526794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.550297</td>\n",
       "      <td>0.214956</td>\n",
       "      <td>24.5</td>\n",
       "      <td>25.898155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.489366</td>\n",
       "      <td>0.212472</td>\n",
       "      <td>20.5</td>\n",
       "      <td>24.294778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.399885</td>\n",
       "      <td>0.341336</td>\n",
       "      <td>20.8</td>\n",
       "      <td>18.736972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.110558</td>\n",
       "      <td>0.596302</td>\n",
       "      <td>11.9</td>\n",
       "      <td>4.675094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.511209</td>\n",
       "      <td>0.381347</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.808909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.183560</td>\n",
       "      <td>0.972682</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.430157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.704158</td>\n",
       "      <td>0.143488</td>\n",
       "      <td>36.1</td>\n",
       "      <td>31.826117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.625216</td>\n",
       "      <td>0.579746</td>\n",
       "      <td>8.4</td>\n",
       "      <td>19.125362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.548764</td>\n",
       "      <td>0.284216</td>\n",
       "      <td>16.1</td>\n",
       "      <td>24.182079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RM     LSTAT  PRICE  PREDICTED_PRICE_SGD\n",
       "0   0.504311  0.546082   11.0            16.638467\n",
       "1   0.727534  0.082781   31.5            33.931732\n",
       "2   0.442422  0.348786   22.0            19.718124\n",
       "3   0.443380  0.197296   50.0            23.406238\n",
       "4   0.519640  0.139349   24.1            26.888865\n",
       "5   0.511401  0.309051   20.1            22.561742\n",
       "6   0.425752  0.450607   22.5            16.801722\n",
       "7   0.612569  0.049669   32.4            31.593653\n",
       "8   0.623683  0.061258   31.6            31.616892\n",
       "9   0.571757  0.533940   10.9            18.773215\n",
       "10  0.498755  0.544426   21.7            16.526794\n",
       "11  0.550297  0.214956   24.5            25.898155\n",
       "12  0.489366  0.212472   20.5            24.294778\n",
       "13  0.399885  0.341336   20.8            18.736972\n",
       "14  0.110558  0.596302   11.9             4.675094\n",
       "15  0.511209  0.381347   19.4            20.808909\n",
       "16  0.183560  0.972682    7.0            -2.430157\n",
       "17  0.704158  0.143488   36.1            31.826117\n",
       "18  0.625216  0.579746    8.4            19.125362\n",
       "19  0.548764  0.284216   16.1            24.182079"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터에서 예측 수행 및 결과를 DataFrame으로 생성. \n",
    "test_predicted_ts = test_ftr_ts[:, 0]*w1 + test_ftr_ts[:, 1]*w2 + bias\n",
    "\n",
    "boston_test_df = pd.DataFrame({\n",
    "    'RM': test_features[:, 0],\n",
    "    'LSTAT': test_ftr_ts[:, 1],\n",
    "    'PRICE': test_tgt_ts,\n",
    "    'PREDICTED_PRICE_SGD': test_predicted_ts.cpu().numpy()\n",
    "})\n",
    "\n",
    "boston_test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e806a39-90f7-4118-86c4-07117e1e09bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.984664879873662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_total_mse = mean_squared_error(boston_test_df['PRICE'], boston_test_df['PREDICTED_PRICE_SGD'])\n",
    "print(test_total_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae6b2c-bf09-43bd-a3ea-8033de3eef28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dbe7cd-aa84-42d6-a80f-c3ab503a64f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
